Breast Cancer Detection: A Deep Learning Approach

#Samruddhi Raut

# OUR CNN Code

import numpy as np
import pydot 
import graphviz
import matplotlib.pyplot as plt
import h5py
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
from keras import backend as K
from keras.models import load_model 
from keras.utils.vis_utils import plot_model
import cv2
import os
from sklearn.model_selection import train_test_split
K.set_image_dim_ordering('tf')

# load data
numepochs=500
batchsize=128
folder_path = 'Downloads/DLNN/Dataset of Mammography with Benign Malignant Breast Masses/INbreast Dataset/' #upload Inbreast and #MIAS dataset
images = []
labels = []
class_label = 0

def load_images_from_folder(folder,class_label):
	for filename in os.listdir(folder):
		img = cv2.imread(os.path.join(folder, filename))
		if img is not None:
			img = cv2.resize(img,(140,92))
			img = img.reshape(92,140,3)
			images.append(img)
			labels.append(class_label)
	class_label=class_label+1
	return class_label

class_label = load_images_from_folder(folder_path+'benign',class_label)
class_label = load_images_from_folder(folder_path+'malignant',class_label)

Data = np.asarray(images)
Labels = np.asarray(labels)

X_train,X_test,y_train,y_test=train_test_split(Data,Labels,test_size=0.2,random_state=2)

# normalize inputs from 0-255 to 0-1
X_train = X_train / 255
X_test = X_test / 255
# one hot encode outputs
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]

#printing sizes
print ("train data shape:")
print (X_train.shape)
print ("test data shape:")
print (X_test.shape)
print ("train label shape:")
print (y_train.shape)
print ("test label shape:")
print (y_test.shape)
#print (y_test)


# define the larger model
def larger_model():
	# create model
	model = Sequential()
	model.add(Conv2D(32, (3, 3), padding="same",input_shape=(92,140,3), activation='relu'))
	#model.add(Conv2D(32, (3, 3), activation='relu',padding = 'same'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Conv2D(32, (3, 3), activation='relu',padding = 'same'))
	#model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same'))
	#model.add(Conv2D(128, (3, 3), activation='relu',padding = 'same'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Dropout(0.5))
	model.add(Flatten())
	model.add(Dropout(0.5))
	model.add(Dense(64, activation='relu'))
	model.add(Dropout(0.5))
	model.add(Dense(64, activation='relu'))
	model.add(Dropout(0.5))
	#model.add(Dense(50, activation='relu'))
	#model.add(Dropout(0.2))
	model.add(Dense(num_classes, activation='softmax'))
	# Compile model
	model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
	return model
	
# build the model
model = larger_model()
# Fit the model
hist=model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=numepochs, batch_size=batchsize)
model.summary()
# Final evaluation of the model
scores = model.evaluate(X_test, y_test, verbose=1,batch_size=batchsize)
model.save('INBreast.h5')
print("Deep Net Accuracy: %.2f%%" % (scores[1]*100))

#testing an image from the test set
print("\n\n***** TESTING AN IMAGE FROM TEST SET *****\n")
test_image = X_test[0:1]
print("Shape of test image 1:")
print (test_image.shape)
print("Predicted accuracies:")
print(model.predict(test_image))
predict_x=model.predict(test_image)
classes_x=np.argmax(predict_x,axis=1)
print("Predicted class:")
print(classes_x)


# visualizing losses and accuracy
train_loss=hist.history['loss']
val_loss=hist.history['val_loss']
train_acc=hist.history['accuracy']
val_acc=hist.history['val_accuracy']

xc=range(numepochs)
plt.figure(1,figsize=(14,7))
#plt.figure(1)
plt.subplot(121)
plt.plot(xc,train_loss)
plt.plot(xc,val_loss)
plt.xlabel('num of Epochs')
plt.ylabel('loss')
plt.title('train_loss vs val_loss')
plt.grid(True)
plt.legend(['train','val'])
#print plt.style.available # use bmh, classic,ggplot for big pictures
plt.style.use(['classic'])

#testing any image
print("\n\n***** TESTING ANY RANDOM IMAGE *****\n")
test_image = cv2.imread('Downloads/DLNN/Dataset of Mammography with Benign Malignant Breast Masses/INbreast Dataset/')
test_image= cv2.resize(test_image,(140,92))
#test_image = test_image.reshape(92,140,3)
test_image = np.array(test_image)
test_image = test_image.astype('float32')
test_image /= 255
test_image= np.expand_dims(test_image, axis=0)
print("Shape of test image 2:")
print (test_image.shape)
print("Predicted accuracies:")
print((model.predict(test_image)))
predict_x=model.predict(test_image)
classes_x=np.argmax(predict_x,axis=1)
print("Predicted class:")
print(classes_x)

#plt.figure(2,figsize=(7,5))
plt.subplot(122)
plt.plot(xc,train_acc)
plt.plot(xc,val_acc)
plt.xlabel('num of Epochs')
plt.ylabel('accuracy')
plt.title('train_acc vs val_acc')
plt.grid(True)
plt.legend(['train','val'],loc=4)
#print plt.style.available # use bmh, classic,ggplot for big pictures
plt.style.use(['classic'])
plt.show()

y_pred = model.predict(X_test, verbose=0)
yhat_classes =np.argmax(y_pred,axis=1)
# reduce to 1d array
y_pred = y_pred[:, 0]
y_test = np.argmax(y_test,axis=1)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, yhat_classes)

from sklearn.metrics import classification_report
print(classification_report(y_test,yhat_classes))


#Transfer_Learning code

import numpy as np # linear algebra
import pandas as pd

import os
for dirname, _, filenames in os.walk('Downloads/samruddhi/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline

import numpy as np
import pandas as pd
import cv2
from PIL import Image
import scipy

import tensorflow as tf
from tensorflow.keras.applications import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.losses import *
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras.callbacks import *
from tensorflow.keras.preprocessing.image import *
from tensorflow.keras.utils import *
# import pydot

from sklearn.metrics import *
from sklearn.model_selection import *
import tensorflow.keras.backend as K

from tqdm import tqdm, tqdm_notebook
from colorama import Fore
import json
import matplotlib.pyplot as plt
import seaborn as sns
from glob import glob
from skimage.io import *
%config Completer.use_jedi = False
import time
from sklearn.decomposition import PCA
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import lightgbm as lgb
import xgboost as xgb

print("All modules have been imported")

info=pd.read_csv("Downloads/input/mias-mammography/Info.txt",sep=" ")
info=info.drop('Unnamed: 7',axis=1)
info.SEVERITY.fillna(0)

#sns.set_style('darkgrid')
fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,5))
sns.barplot(x=info.BG.unique(),y=info.BG.value_counts(),palette='Blues_r',ax=ax1)
sns.barplot(x=info.CLASS.unique(),y=info.CLASS.value_counts(),palette='Blues_r',ax=ax2)

#from PIL import Image
import glob
x= []
for filename in sorted(glob.glob("Downloads/input/mias-mammography/all-mias/*.pgm")): 
    img=cv2.imread(filename)
    img =cv2.resize(img,(224, 224))
    x.append(img)
fig=plt.figure(figsize=(15,15))
columns = 3
rows = 3
for i in range(1, columns*rows +1):
    img = np.random.randint(10)
    fig.add_subplot(rows, columns, i)
    plt.imshow(x[i])
plt.show()

# Image Augmentation
no_angles = 360
url = 'Downloads/input/mias-mammography/all-mias/'

def save_dictionary(path,data):
        print('saving catalog...')
        #open('u.item', encoding="utf-8")
        import json
        with open(path,'w') as outfile:
            json.dump(str(data), fp=outfile)
        # save to file:
        print(' catalog saved')

# train_test_split_datagen=ImageDataGenerator("augmentations such as flip,brightness range,etc....")
# val_datagen=ImageDataGenerator("augmentations such as flip,brightness range,etc....")
# test_datagen=ImageDataGenerator("augmentations such as flip,brightness range,etc....")
def read_image():
        print("Reading images")
        import cv2
        info = {}
        for i in range(322):
            if i<9:
                image_name='mdb00'+str(i+1)
            elif i<99:
                image_name='mdb0'+str(i+1)
            else:
                image_name = 'mdb' + str(i+1)
            image_address= url+image_name+'.pgm'
            img = cv2.imread(image_address,1)
            img = cv2.resize(img, (224,224))
            rows, cols,channel = img.shape
            info[image_name]={}
            for angle in range(0,no_angles,8):
                M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1) 
                img_rotated = cv2.warpAffine(img, M, (cols, rows))
                info[image_name][angle]=img_rotated
        return (info)


def read_lable():
    print("Reading labels")
    filename = url+'Info.txt'
    text_all = open(filename).read()
    #print(text_all)
    lines=text_all.split('\n')
    info={}
    for line in lines:
        words=line.split(' ')       
        if len(words)>3:
            if (words[3] == 'B'):
                info[words[0]] = {}
                for angle in range(0,no_angles,8):
                    info[words[0]][angle] = 0
            if (words[3] == 'M'):
                info[words[0]] = {}
                for  angle in range(0,no_angles,8):
                    info[words[0]][angle] = 1
    return (info)


import numpy as np
lable_info=read_lable()
image_info=read_image()
ids=lable_info.keys() 
del lable_info['Truth-Data:']
X=[]
Y=[]
for id in ids:
    for angle in range(0,no_angles,8):
        X.append(image_info[id][angle])
        Y.append(lable_info[id][angle])
X=np.array(X)
Y=np.array(Y)
Y=to_categorical(Y,2)
x_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.3, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.3, random_state=42)
print(len(x_train),len(x_val),len(x_test))

#Callbacks
c2=tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0,
    patience=6,
    mode="auto",
    baseline=None,
    restore_best_weights=True,
)

c3=tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.1,
    patience=6,
    mode="auto",
    min_delta=0.0001,
    cooldown=0,
    min_lr=0.001
)
nClasses=3

#InceptionV3
base_Neural_Net= InceptionV3(input_shape=(224,224,3), weights='imagenet', include_top=False)
model=Sequential()
model.add(base_Neural_Net)
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(256,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='softmax'))

for layer in base_Neural_Net.layers:
    layer.trainable = False

c1=PlotLossesKeras()
model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])
history=model.fit(x_train,y_train,epochs=100,callbacks=[c1,c3],batch_size=16)

model.evaluate(x_val,y_val,callbacks=[c2,c3],batch_size=16)

print("Performance Report:")

#y_pred7=model.predict_classes(x_test)
predict_y=model.predict(x_test) 
y_pred7=np.argmax(predict_y,axis=1)

y_test7=[np.argmax(x) for x in y_test]

#y_pred_prb7=model.predict_proba(x_test)
y_pred_prb7 = np.array(list(map(predict_prob, model.predict(x_test))))

target=["B","M"]
from sklearn import metrics
print('Accuracy score is :', np.round(metrics.accuracy_score(y_test7, y_pred7),4))
print('Precision score is :', np.round(metrics.precision_score(y_test7, y_pred7, average='weighted'),4))
print('Recall score is :', np.round(metrics.recall_score(y_test7,y_pred7, average='weighted'),4))
print('F1 Score is :', np.round(metrics.f1_score(y_test7, y_pred7, average='weighted'),4))
print('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test7, y_pred7,multi_class='ovo', average='weighted'),4))
print('\t\tClassification Report:\n', metrics.classification_report(y_test7, y_pred7,target_names=target))
print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test7, y_pred7),4))

#DenseNet121
base_Neural_Net=DenseNet121(input_shape=(224,224,3), weights='imagenet', include_top=False)
model=Sequential()
model.add(base_Neural_Net)
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(256,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='softmax'))

for layer in base_Neural_Net.layers:
    layer.trainable = False

c1=PlotLossesKeras()
model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])
history=model.fit(x_train,y_train,epochs=100,callbacks=[c1,c3],batch_size=16)

model.evaluate(x_val,y_val,callbacks=[c2,c3],batch_size=16)

print("Performance Report:")

#y_pred11=model.predict_classes(x_test)
predict_y=model.predict(x_test) 
y_pred11=np.argmax(predict_y,axis=1)

y_test11=[np.argmax(x) for x in y_test]

#y_pred_prb11=model.predict_proba(x_test)
def predict_prob(number):
  return [number[0],1-number[0]]
y_pred_prb11 = np.array(list(map(predict_prob, model.predict(x_test))))

target=["B","M"]
from sklearn import metrics
print('Accuracy score is :', np.round(metrics.accuracy_score(y_test11, y_pred11),4))
print('Precision score is :', np.round(metrics.precision_score(y_test11, y_pred11, average='weighted'),4))
print('Recall score is :', np.round(metrics.recall_score(y_test11,y_pred11, average='weighted'),4))
print('F1 Score is :', np.round(metrics.f1_score(y_test11, y_pred11, average='weighted'),4))
print('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test11, y_pred11,multi_class='ovo', average='weighted'),4))
print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test11, y_pred11),4))
print('\t\tClassification Report:\n', metrics.classification_report(y_test11, y_pred11,target_names=target))

#MobileNetV2

base_Neural_Net=MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)
model=Sequential()
model.add(base_Neural_Net)
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(256,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='softmax'))

for layer in base_Neural_Net.layers:
    layer.trainable = False

c1=PlotLossesKeras()
model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])
history=model.fit(x_train,y_train,epochs=100,callbacks=[c1,c3],batch_size=16)

model.evaluate(x_val,y_val,callbacks=[c2,c3],batch_size=16)


#y_pred12=model.predict_classes(x_test)
predict_y=model.predict(x_test) 
y_pred12=np.argmax(predict_y,axis=1)

y_test12=[np.argmax(x) for x in y_test]

#y_pred_prb12=model.predict_proba(x_test)
y_pred_prb12 = np.array(list(map(predict_prob, model.predict(x_test))))

target=["B","M"]
from sklearn import metrics
print('Accuracy score is :', np.round(metrics.accuracy_score(y_test12, y_pred12),4))
print('Precision score is :', np.round(metrics.precision_score(y_test12, y_pred12, average='weighted'),4))
print('Recall score is :', np.round(metrics.recall_score(y_test12,y_pred12, average='weighted'),4))
print('F1 Score is :', np.round(metrics.f1_score(y_test12, y_pred12, average='weighted'),4))
print('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test12, y_pred12,multi_class='ovo', average='weighted'),4))
print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test12, y_pred12),4))
print('\t\tClassification Report:\n', metrics.classification_report(y_test12, y_pred12,target_names=target))

#ResNet50
base_Neural_Net=ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)
model=Sequential()
model.add(base_Neural_Net)
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(256,kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='softmax'))
for layer in base_Neural_Net.layers:
    layer.trainable = False

c1=PlotLossesKeras()
model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])
history=model.fit(x_train,y_train,epochs=100,callbacks=[c1,c3],batch_size=16)

model.evaluate(x_val,y_val,callbacks=[c2,c3],batch_size=16)

print("Performance Report:")

#y_pred6=model.predict_classes(x_test)
predict_y=model.predict(x_test) 
y_pred5=np.argmax(predict_y,axis=1)

y_test5=[np.argmax(x) for x in y_test]

#y_pred_prb6=model.predict_proba(x_test)
def predict_prob(number):
  return [number[0],1-number[0]]
y_pred_prb5 = np.array(list(map(predict_prob, model.predict(x_test))))

target=["B","M"]
from sklearn import metrics
print('Accuracy score is :', np.round(metrics.accuracy_score(y_test5, y_pred5),4))
print('Precision score is :', np.round(metrics.precision_score(y_test5, y_pred5, average='weighted'),4))
print('Recall score is :', np.round(metrics.recall_score(y_test5,y_pred5, average='weighted'),4))
print('F1 Score is :', np.round(metrics.f1_score(y_test5, y_pred5, average='weighted'),4))
print('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test5, y_pred5,multi_class='ovo', average='weighted'),4))
print('\t\tClassification Report:\n', metrics.classification_report(y_test5, y_pred5,target_names=target))
print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test5, y_pred5),4))


